---
title: "Housing Data Analysis"
author: "Arindam Samanta"
date: January 19 2020
output:
  
  word_document: default
---

```{r setup,echo=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

    Explain why you choose to remove data points from your ‘clean’ dataset.



## Part 
### Source for the Housing data 

Data for this assignment is focused on real estate transactions recorded from 1964 to 2016 and can be found in Week 7 Housing.xlsx. Using your skills in statistical correlation, multiple regression and R programming, you are interested in the following variables:  Sale Price and several other possible predictors.

## Data Preparations and cleaning the data
We have used the following libraries for our regression analysis. Regression analysis is used in stats to find trends in data. For example, we are trying to predict the sale price of the house based on some predictors and using regression analysis can help us quantify that.
```{r loading_packages, echo = TRUE, results='hide', warning=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(corrplot)
library(readxl)
```
## 
Reading the excel sheet and loading the rows into a data frame. Then looking through the data using glimpse function. It shows that the sample has 12,865 observations and 24 variables. Each row represents a single house.
That looks like a lot of variables so we would chose our variables that would be used for our prediction model and ignore the others. So essentially creating a smaller set of data with less variables.
```{r , echo=TRUE, results='hide'}
#populating the housing_data dataframe
wd <- getwd()
fname <- "week-7-housing.xlsx"
path_to_file <- paste(wd,'/dataset/',fname, sep = "")
path_to_file

housing_data <- read_excel(path_to_file,col_names=TRUE)
glimpse(housing_data)

head(housing_data)

#Selecting only some variables from the dataframe into our analysis dataframe set 1
housing_data_set1 <- housing_data %>%
  select (`Sale Price`,`Sale Date`,bath_full_count, sq_ft_lot,bedrooms)
```
Now we start looking at the dataset

```{r }
# looking at the first few rows
head(housing_data_set1)
```

Summaize the data based on each of the columns to see how the distribution looks

```{r}
## Summarizing the data set by bath_full_count
housing_data_set1 %>%
  group_by(bath_full_count) %>%
  summarize("# of houses" = n())

```
We can consider bath count to be a categorical variable. There are 8 distinct bath counts in the data set. Now lets look at the other categorical variable bedrooms.

```{r}
## Summarizing the data set by # of bedrooms
housing_data_set1 %>%
  group_by(bedrooms) %>%
  summarize("# of houses" = n())

```
The summarized data shows that there are 12 distinct bedroom counts for the dataset.

```{r}
## Summarizing the data set by # of bedrooms
  summary(housing_data_set1$`Sale Price`)

```
```{r }
# Counting the number of houses with the Min and Max sale price
housing_data_set1 %>%
  ## filter(`Sale Price` == 4400000)
  ## filter(sq_ft_lot == 6635)
  filter(bath_full_count == 3 & bedrooms == 5)
```

Now lets convert the bath_full_count and bedrooms to factors and create a .mod dataset

```{r}

housing_data_set1.mod <- housing_data_set1

  housing_data_set1.mod$bedrooms <- as.factor(housing_data_set1.mod$bedrooms)
  housing_data_set1.mod$bath_full_count <- as.factor(housing_data_set1.mod$bath_full_count)
  housing_data_set1.mod$`Sale Date` <- as.Date(housing_data_set1.mod$`Sale Date`)
  
  glimpse(housing_data_set1.mod)
```
Use pairs function to measure the correlation among the variables.
```{r}
pairs(housing_data_set1.mod)
```
### Create two variables; one that will contain the variables Sale Price and Square Foot of Lot (same variables used from previous assignment on simple regression) and one that will contain Sale Price, Bedrooms, and Bath Full Count as predictors.  


Use ggplot to make a scatter plot for Sale Price as a function of sq foot of lot size.

```{r}

ggplot(data = housing_data_set1.mod, aes(x = sq_ft_lot, y = `Sale Price`)) +
  geom_point() +
  labs( title = "Plotting Sale Price against Lot size",
        x = "Lot size in sq ft",
        y = "Price in '000s")

```


Use lm() to fit a simple linear regression model for Price as a function of Lot size.

```{r}
var1 <- lm(`Sale Price` ~ sq_ft_lot, data = housing_data_set1.mod)

```
Using lm() to fit a multiple regression model with 2 new predictors like bedrooms and bath_full_count

```{r}
var2 <- lm(`Sale Price` ~ as.numeric(bedrooms) + as.numeric(bath_full_count), data = housing_data_set1.mod)

```
 
### Execute a summary() function on two variables defined in the previous step to compare the model results. What are the R2 and Adjusted R2 statistics?  Explain what these results tell you about the overall model. Did the inclusion of the additional predictors help explain any large variations found in Sale Price?

```{r, Model 1 and Model 2}
summary(var1)

predict(var1, data.frame(sq_ft_lot = 6635))

summary(var2)
predict(var2, data.frame(bedrooms = 5, bath_full_count = 3))
``` 

### Considering the parameters of the multiple regression model you have created. What are the standardized betas for each parameter and what do the values indicate?
### Calculate the confidence intervals for the parameters in your model and explain what the results indicate.
### Assess the improvement of the new model compared to your original model (simple regression model) by testing whether this change is significant by performing an analysis of variance.
 
    Perform casewise diagnostics to identify outliers and/or influential cases, storing each functions output in a dataframe assigned to a unique variable name.
    Calculate the standardized residuals using the appropriate command, specifying those that are +-2, storing the results of large residuals in a variable you create.
    Use the appropriate function to show the sum of large residuals.
    Which specific variables have large residuals (only cases that evaluate as TRUE)?
    Investigate further by calculating the leverage, cooks distance, and covariance rations. Comment on all cases that are problematics.
    Perform the necessary calculations to assess the assumption of independence and state if the condition is met or not.
    Perform the necessary calculations to assess the assumption of no multicollinearity and state if the condition is met or not.
    Visually check the assumptions related to the residuals using the plot() and hist() functions. Summarize what each graph is informing you of and if any anomalies are present.
    Overall, is this regression model unbiased?  If an unbiased regression model, what does this tell us about the sample vs. the entire population model?
 
 
 
 
 
 Use lm() to fit a parallel slopes model for Price as a function of Food and East. Interpret the coefficients and the fit of the model. Can you explain the meaning of the coefficient on East in simple terms? Did the coefficient on Food change from the previous model? If so, why? Did it change by a lot or just a little? 


# fit model: Use lm() to fit a multiple regression model for Price as a function of Food and Service
lm(Price ~ Food + Service, data = nyc)

# draw 3D scatterplot: Use plot_ly to draw 3D scatterplot for Price as a function of Food and Service by mapping the z variable to the response and the x and y variables to the explanatory variables. Place the food quality on the x-axis and service rating on the y-axis.
p <- plot_ly(data = nyc, z = ~Price, x = ~Food, y = ~Service, opacity = 0.6) %>%
  add_markers() 

# draw a plane: Use add_surface() to draw a plane through the cloud of points using the object plane.
p %>%
  add_surface(x = ~x, y = ~y, z = ~plane, showscale = FALSE) 
  
  Use lm() to fit a parallel planes model for Price as a function of Food, Service, and East.
  
  # Price by Food and Service and East
lm(Price ~ Food + Service + East, data = nyc)


Another way is to examine the impact of location in the context of the variability of the other variables. We can do this by building our parallel planes in 3D and seeing how far apart they are. Are the planes close together or far apart? Does the East variable clearly separate the data into two distinct groups? Or are the points all mixed up together?


    Use plot_ly to draw 3D scatterplot for Price as a function of Food, Service, and East by mapping the z variable to the response and the x and y variables to the numeric explanatory variables. Use color to indicate the value of East. Place Food on the x-axis and Service on the y-axis.
    # draw 3D scatterplot
p <- plot_ly(data = nyc, z = ~Price, x = ~Food, y = ~Service, opacity = 0.6) %>%
  add_markers(color = ~factor(East)) 
  
    Use add_surface() (twice) to draw two planes through the cloud of points, one for restaurants on the West side and another for restaurants on the East side. Use the objects plane0 and plane1.

# draw two planes
p %>%
  add_surface(x = ~x, y = ~y, z = ~plane0, showscale = FALSE) %>%
  add_surface(x = ~x, y = ~y, z = ~plane1, showscale = FALSE)
  
  
  Use lm() to fit a parallel planes model for Price as a function of Food, Service, Decor, and East.

Notice the dramatic change in the value of the Service coefficient. 
